{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import tensorflow as tf\n",
        "\n",
        "# Optionally, print devices to confirm no GPU is being used\n",
        "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "JMgv_f94bJ8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Qzaf8d5xtwX"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python fer pywhatkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "from IPython.display import display, HTML, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import matplotlib.pyplot as plt\n",
        "from fer import FER"
      ],
      "metadata": {
        "id": "2p-eQGWFyHvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "      async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const captureButton = document.createElement('button');\n",
        "        captureButton.textContent = 'Capture';\n",
        "        div.appendChild(captureButton);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Adjust the iframe height to fit the video element.\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        // Wait for the user to click the capture button.\n",
        "        await new Promise((resolve) => captureButton.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "        return canvas.toDataURL('image/jpeg', quality);\n",
        "      }\n",
        "      ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = base64.b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename"
      ],
      "metadata": {
        "id": "iZI2C9OGXShS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = take_photo()\n",
        "print(\"Photo saved as:\", filename)"
      ],
      "metadata": {
        "id": "QhJkXxB-aFVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(filename)\n",
        "if img is None:\n",
        "    print(\"Error: Could not load the image. Please try again.\")\n",
        "else:\n",
        "    # Display the captured image inline\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Captured Image\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kiTRT1NIaS58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_detector = FER(mtcnn=True)"
      ],
      "metadata": {
        "id": "chLnV8yUaW8H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = emotion_detector.detect_emotions(img)\n",
        "if results:\n",
        "    top_emotion, score = emotion_detector.top_emotion(img)\n",
        "    print(f\"Detected emotion: {top_emotion} with confidence {score:.2f}\")\n",
        "\n",
        "    # Map detected emotion to a song suggestion\n",
        "    song_mapping = {\n",
        "        'happy': 'Happy - Pharrell Williams',\n",
        "        'sad': 'Someone Like You - Adele',\n",
        "        'angry': 'Break Stuff - Limp Bizkit',\n",
        "        'surprise': 'Surprise Yourself - Jack Garratt',\n",
        "        'neutral': 'Best Day of My Life - American Authors'\n",
        "    }\n",
        "    song = song_mapping.get(top_emotion.lower(), song_mapping['neutral'])\n",
        "    #print(\"Suggested song:\", song)\n",
        "\n",
        "    # Create a YouTube search URL for the song\n",
        "    query = song.replace(\" \", \"+\")\n",
        "    url = f\"https://www.youtube.com/results?search_query={query}\"\n",
        "\n",
        "    # Display a clickable link to the YouTube search results\n",
        "    display(HTML(f\"<a href='{url}' target='_blank'>Click here to play the song on YouTube</a>\"))\n",
        "else:\n",
        "    print(\"No face or emotion detected in the image.\")"
      ],
      "metadata": {
        "id": "4lrf3DT8aalS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}